{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from ephys import rasters, core, events\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "%pylab inline\n",
    "#reload(rasters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephys import core, events, rasters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from oe_pipeline import mdaio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyMNE_functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block_path = '/mnt/cube/nyoni-raw/test_data/201901300906-B970-block-9-AP-1250-ML-750-Z-1750'\n",
    "block_path = '/mnt/cube/mturvz/analysis/sorted_experiments/0227/B1146/blocks/201902271608-B1146-block-2-AP-2300-ML-400-Z-1550/2019-02-27_16-08-48'\n",
    "#block_path = 'mnt/cube/Nasim/1_Receptive Field_MNE/2_B952/B952_2_Pen01_Lft_AP750_ML1750__Site01_Z1500__B952_cat_P01_S01_2'\n",
    "\n",
    "\n",
    "spikes = core.load_spikes(block_path)\n",
    "trials = events.oe_load_trials(block_path)\n",
    "fs = core.load_fs(block_path)\n",
    "clusters = core.load_clusters(block_path)\n",
    "#clusters['quality'] = ['good'] * 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def oe_load_trials(block_path):\n",
    "TRIAL_CHANNEL = 0    \n",
    "ttls = core.load_events(block_path, 'TTL')\n",
    "stimuli = core.load_events(block_path, 'Stimulus')\n",
    "\n",
    "trial_starts = ttls[(ttls.channel == TRIAL_CHANNEL) & (ttls.eventID==1)]['time_samples'].values\n",
    "trial_ends = ttls[(ttls.channel == TRIAL_CHANNEL) & (ttls.eventID==0)]['time_samples'].values\n",
    "#stims = [x.decode('utf8') for x in stimuli['text'].values]\n",
    "#time_samples = stimuli['time_samples'].values\n",
    "#stimulus_end = stimuli['stimulus_end'].values  \n",
    "#trials = pd.DataFrame({'trial_start': trial_starts, 'trial_end': trial_ends, 'time_samples': time_samples, 'stimulus_end': stimulus_end, 'stimulus': stims})\n",
    "#return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stims = trials['stimulus'].unique()\n",
    "nstims = len(stims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raster_cell_stim(spikes, trials, clusterID,\n",
    "                          stim, period, rec, fs, ax=None, stim_ref='stim', **kwargs):\n",
    "    '''\n",
    "    Plots a spike raster for a single cell and stimulus\n",
    "    Parameters\n",
    "    ------\n",
    "    spikes : pandas dataframe\n",
    "        spike dataframe from core\n",
    "    trials : pandas dataframe\n",
    "        trials dataframe from events\n",
    "    clusterID : int\n",
    "        ID number of the cluster you wish to make the raster for\n",
    "    stim : str\n",
    "        Name of the stimulus you wish to plot cluster's activity for\n",
    "    period : list of floats\n",
    "        Time window for the raster:\n",
    "        [Seconds_pre_stimulus_onset, Seconds_post_stimulus_end]\n",
    "    rec : int\n",
    "        Recording ID\n",
    "    fs : float\n",
    "        Sampling rate\n",
    "    plot_params : dict\n",
    "        Drawing parameters:\n",
    "        'spike_linewidth' - linewidth of ticks for spikes\n",
    "        'tick_linewidth' - linewidth of ticks for event markers\n",
    "        'spike_color' - color of spike ticks\n",
    "        'tick_color' - color of event ticks\n",
    "    ax : Matplotlib axes handle, optional\n",
    "        Axes on which to produce the raster.  Default is to use gca\n",
    "    kwargs :\n",
    "        keyword arguments are passed to the do_raster method\n",
    "    '''\n",
    "    from ephys.spiketrains import get_spiketrain\n",
    "    stim_trials = trials[trials['stimulus'] == stim]\n",
    "    ntrials = len(stim_trials)\n",
    "    stim_starts = stim_trials['time_samples'].values\n",
    "    stim_ends = stim_trials['stimulus_end'].values\n",
    "    stim_end_seconds = np.unique((stim_ends - stim_starts) / fs)[0]\n",
    "    if stim_ref == 'stim':\n",
    "        window = [period[0], stim_end_seconds + period[1]]\n",
    "    elif stim_ref == 'abs':\n",
    "        window = [period[0], period[1]]\n",
    "    raster_data = []\n",
    "    for trial, start in enumerate(stim_starts):\n",
    "        sptrain = get_spiketrain(rec, start, clusterID, spikes, window, fs)\n",
    "        raster_data.append(sptrain)\n",
    "    #ax = do_raster(raster_data, window, [0, stim_end_seconds], ntrials, ax, **kwargs)\n",
    "    return raster_data, stim_end_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get raster data for all clusters\n",
    "n_units = len(clusters)\n",
    "raster_data = []\n",
    "stim_end_seconds = [[None]*len(stims)]*n_units\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    r_cluster = []\n",
    "    for j in range(len(stims)):           \n",
    "        r_data, stim_end_seconds[i][j] = plot_raster_cell_stim(spikes, trials, clusters['cluster'][i], stims[j], [-2, 2], 0, 30000.0)\n",
    "        r_cluster.append(r_data)\n",
    "    raster_data.append(r_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.collections.EventCollection at 0x7f9ac7ef2390>,\n",
       " <matplotlib.collections.EventCollection at 0x7f9ac7e92978>,\n",
       " <matplotlib.collections.EventCollection at 0x7f9ac7e9b710>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ntrials = len(trials)\n",
    "spike_linewidth=1.5\n",
    "spike_color='k'\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(range(-1, ntrials-1))\n",
    "ax.figure.set_size_inches(20, 5)\n",
    "xposition = [0, stim_end_seconds[1][16]]\n",
    "for xc in xposition:\n",
    "    plt.axvline(x=xc, color='r', linestyle='-')\n",
    "ax.eventplot(raster_data[16][1], linewidths=spike_linewidth, colors=spike_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get stimulus information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Confirm with Michael on how to find start and end time sof stimulus\n",
    "import pandas as pd\n",
    "d = []\n",
    "for s in stims:\n",
    "    ind = np.where(trials['stimulus'] == s)[0]\n",
    "    d.append({'name' : s, \n",
    "              'start_times' : [trials['time_samples'][i] for i in ind], \n",
    "              'end_times' : [trials['stimulus_end'][i] for i in ind],\n",
    "              'trial_start' : [trials['trial_start'][i] for i in ind], \n",
    "              'trial_end' : [trials['trial_end'][i] for i in ind],\n",
    "              'ntrials' : (list(trials['stimulus'])).count(s)})\n",
    "stim_data = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get toe data, toes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make cluster_stim_data dataframe, one for each cluster\n",
    "### name, ntrials, stim_start_times, stim_end_times, trial_start_times, trial_end_times, toes\n",
    "d_stim = []\n",
    "for i in range(len(clusters)):\n",
    "    d_stim.append({'name':list(stims), \n",
    "                   'ntrials':stim_data['ntrials'].tolist(), \n",
    "                   'stim_start_times':stim_data['start_times'].tolist(), \n",
    "                   'stim_end_times':stim_data['end_times'].tolist(), \n",
    "                   'trial_start_times':stim_data['trial_start'].tolist(), \n",
    "                   'trial_end_times':stim_data['trial_end'].tolist(), \n",
    "                   'toes':raster_data[i]})\n",
    "cluster_stim_data = pd.DataFrame(d_stim)\n",
    "cluster_stim_data = cluster_stim_data.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make toe_data pandas dataframe, one for each cluster\n",
    "### cluster id, sort class, fs, stims, all_spikes\n",
    "d1 = []\n",
    "for i in range(len(clusters)):\n",
    "    ind = np.where(np.array(spikes['cluster']) == i+1)[0]\n",
    "    d1.append({'id':clusters['cluster'][i], \n",
    "               'sort_class':clusters['quality'][i], \n",
    "               'fs':30000, \n",
    "               'stims':cluster_stim_data[i], \n",
    "               'all_spikes':[spikes['time_samples'][j] for j in ind]})\n",
    "toe_data = pd.DataFrame(d1)\n",
    "toe_data = toe_data.to_dict(orient='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stim prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed\n",
    "\n",
    "from glob import glob\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import imp\n",
    "folder_utils = imp.load_source('folder_utils', r'/mnt/cube/srrudrar/folder_utils.py')\n",
    "ensure_folder_exists = folder_utils.ensure_folder_exists\n",
    "\n",
    "import h5py, os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import librosa\n",
    "import librosa.filters\n",
    "import numpy as np\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, lfilter, spectrogram\n",
    "from scipy.io import wavfile\n",
    "import IPython.display\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write a better way to get spectrograms\n",
    "### Get spectrogram\n",
    "import os\n",
    "stim_folder = '/mnt/cube/mturvz/analysis/sorted_experiments/0227/20181116/'\n",
    "T = []\n",
    "P = []\n",
    "P_all = []\n",
    "nfft = 128\n",
    "\n",
    "for i in range(len(stims)):\n",
    "    rate, data = wavfile.read(os.path.join(stim_folder, stims[i]))\n",
    "    #spec = spectrogram(data, hparams)\n",
    "    (f, t_stim, P_stim) = sp.signal.spectrogram(data[:,0], fs = 48000, nfft = 128, \n",
    "                                            window = np.hanning(nfft), noverlap = 0.5*nfft)\n",
    "    #P_stims, freqs, bins, im = plt.specgram(data[:,0], nfft = 128, fs = 48000, noverlap = 0.5*nfft)\n",
    "    P.append(P_stim)\n",
    "    T.append(t_stim)\n",
    "P_all = np.hstack(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nf = 16       # number of frequency bands in STRF\n",
    "Nlags = 20    # number of times/lags\n",
    "order   = 2   # order of MNE model to fit: order 1=linear part of equation,  order=2: linear and non linear parts\n",
    "fittype = 0   # to intialize: 0 for regular fitting, 1 for random fitting  \n",
    "njack   = 4\n",
    "Nd = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srrudrar/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "### Please write better code than this ! :/\n",
    "from scipy import stats\n",
    "P_all_mean = np.empty([16,np.shape(P_all)[1]])\n",
    "for i in range(16):\n",
    "    P_all_mean[i,:] = np.mean((20 * np.log(P_all))[4*i:(4*(i+1))-1 , :], axis = 0)\n",
    "\n",
    "tsamples = int(np.shape(P_all)[1]/8)\n",
    "P_mean = np.empty([16,tsamples])\n",
    "for i in range(tsamples):\n",
    "    P_mean[:,i] = np.mean(P_all_mean[: , 8*i:(8*(i+1))-1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srrudrar/anaconda3/envs/tensorflow/lib/python3.6/site-packages/numpy/core/_methods.py:117: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      "/home/srrudrar/anaconda3/envs/tensorflow/lib/python3.6/site-packages/scipy/stats/stats.py:2253: RuntimeWarning: invalid value encountered in subtract\n",
      "  return (a - mns) / sstd\n"
     ]
    }
   ],
   "source": [
    "stimulus = stats.zscore(P_mean)\n",
    "[Ndim, Nsamples] = np.shape(stimulus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Nlags > 1:\n",
    "    Nsamples_lag = Nsamples - Nlags + 1    #total length of stimulus minus 19 time bins (16000=16119-(20-1))\n",
    "    Ndimtotal = Ndim * Nlags           #16x20\n",
    "    stim = stimulus[:,0:Nsamples_lag]\n",
    "    for i in range(1,Nlags):\n",
    "        stim = np.vstack((stim, stimulus[:,i:Nsamples_lag+i])) \n",
    "else:\n",
    "    stim = stimulus        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resp prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellnum = 21\n",
    "toedata_ind = pd.Index(list(clusters['cluster'])).get_loc(cellnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "toes_stim = []\n",
    "for i in range(len(stims)):\n",
    "    toes_stim.append(toe_data[toedata_ind]['stims']['toes'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create trial average of every 5 trials for all stim \n",
    "### how many trials in this case\n",
    "Nlags = 20\n",
    "Nf = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = []\n",
    "for s in range(len(stims)):\n",
    "    timetobin = np.shape(P[s])[1] / T[s][-1]\n",
    "    resp_stim = np.zeros(shape=(stim_data['ntrials'][s] , np.shape(P[s])[1]))\n",
    "    #resp_stim = [[None]*np.shape(P[s])[1]]*stim_data['ntrials'][s]\n",
    "    for k in range(stim_data['ntrials'][s]):\n",
    "        toes_this_trial = []\n",
    "        toes_this_trial = toes_stim[s][k]\n",
    "        for m in range(len(toes_this_trial)):\n",
    "            if toes_this_trial[m] > 0 and  toes_this_trial[m] * timetobin < np.shape(P[s])[1]:\n",
    "                resp_stim[k , int(round(toes_this_trial[m])*timetobin)] = resp_stim[k , int(round(toes_this_trial[m])*timetobin)] + 1\n",
    "                #resp_1(k,round(A_1(m_1).*timetobin_1)) = resp_1(1,round(A_1(m_1).*timetobin_1)) + 1;\n",
    "    resp.append(list(resp_stim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(stims)):\n",
    "    if len(resp[i]) == 2:\n",
    "        resp[i].append(resp[i][1])\n",
    "    if len(resp[i]) == 1:\n",
    "        resp[i].append(resp[i][0])\n",
    "        resp[i].append(resp[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_123 = [None]*3\n",
    "for i in range(3):\n",
    "    resp_123[i] = np.hstack(resp[j][i] for j in range(len(stims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### downsample stimuli\n",
    "resp_123_downsize = np.empty([3,tsamples])\n",
    "for j in range(3):\n",
    "    for i in range(tsamples):\n",
    "        resp_123_downsize[j][i] = np.mean(resp_123[j][8*i:(8*(i+1))-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.mean(resp_123_downsize, axis=0)\n",
    "response = a[Nlags-1:]/(np.amax(a[Nlags:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterstim = np.transpose(stim)    #104040x320\n",
    "masterresp = response    #104040x1\n",
    "master_samples = len(masterstim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "njack = 4\n",
    "Ntest = int(master_samples/njack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Starting optimization'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####\n",
    "jack = 3\n",
    "Ntest = int(master_samples/njack)    #  rounds the Ntest to the nearest integers \n",
    "ind = range(jack*Ntest,(jack+1)*Ntest)\n",
    "teststim = masterstim[jack*Ntest : (jack+1)*Ntest, :]\n",
    "testresp = masterresp[jack*Ntest : (jack+1)*Ntest]\n",
    "trainstim = np.delete(masterstim, ind, axis = 0) \n",
    "trainresp = np.delete(masterresp, ind)\n",
    "\n",
    "# Start optimization: look for highest P(resp/stim)=1/(1+exp(a+sh+s^t*J*s)^-1\n",
    "display('Starting optimization')\n",
    "#tic()\n",
    "#celltype = '';  #ignore this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNEfit(stim, resp, teststim, testresp, celltype, cellnum, jack, order, Nd, fittype);\n",
    "[Nsamples_2,Ndim_2] = np.shape(trainstim)\n",
    "psp = np.mean(trainresp)   #constant parameter a\n",
    "avg = (np.dot(np.transpose(trainstim),trainresp))/Nsamples_2  # h: linear\n",
    "avgs = np.concatenate(([psp],avg), axis = 0)\n",
    "\n",
    "if order>1:\n",
    "    a = np.transpose(np.matlib.repmat(trainresp,Ndim_2,1))\n",
    "    b = np.multiply(a,trainstim)\n",
    "    avgsqrd = np.dot(np.transpose(trainstim),b)/Nsamples_2  #Ndim x Ndim (320x320)\n",
    "    avgsqrd = avgsqrd.flatten()\n",
    "    avgs = np.concatenate((avgs,avgsqrd), axis = 0)\n",
    "\n",
    "pstart = np.empty(np.shape(avgs))\n",
    "pstart[0] = math.log((1/avgs[0]) - 1)     #pstart(a)\n",
    "random = np.random.rand(Ndim_2)\n",
    "pstart[1:Ndim_2+1] = 0.001*((2*random)-1)\n",
    "if order>1:\n",
    "    random1 = np.random.rand(Ndim_2,Ndim_2)\n",
    "    temp = 0.001*((2*random1)-1)          #pstart(J)\n",
    "    pstart[Ndim_2+1:] = (temp+np.transpose(temp)).reshape([1,Ndim_2**2])\n",
    "    del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,*args):\n",
    "    p = x\n",
    "    order = 2\n",
    "    trainstim, trainresp, order = args\n",
    "    return log_loss(p,trainstim,trainresp,order)\n",
    "\n",
    "def gradf(x,*args):\n",
    "    p = x\n",
    "    order = 2\n",
    "    trainstim, avgs, order = args\n",
    "    return d_log_loss(p,trainstim,avgs,order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-809477ee99fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#pfinal = opt.fmin_cg(f,pstart,fprime=gradf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmin_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainstim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainresp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_log_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainstim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'log_loss' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as opt\n",
    "#pfinal = opt.fmin_cg(f,pstart,fprime=gradf)\n",
    "pfinal = opt.fmin_cg(log_loss(pstart,trainstim,trainresp,order),pstart,fprime=d_log_loss(pstart,trainstim,avgs,order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dlinmin():\n",
    "    TOL = 2.0e-4\n",
    "    nrfunc = func \n",
    "    nrdfun = dfunc \n",
    "    pcom   = p \n",
    "    xicom  = xi \n",
    "    \n",
    "    ax = 0.0       #Initial guess for brackets\n",
    "    xx = 0.2       #2*rand();%2.0;\n",
    "    \n",
    "    ftemp = @f1dim\n",
    "    ftemp2 = @df1dim\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [p, xi, fret] = dlinmin(p, xi, func, dfunc, stim, resp, order, avgs)\n",
    " \n",
    "TOL    = 2.0e-4;  % Tolerance passed to brent. \n",
    "\n",
    "global pcom xicom nrfunc nrdfun; \n",
    "nrfunc = func; \n",
    "nrdfun = dfunc; \n",
    "pcom   = p; \n",
    "xicom  = xi; \n",
    " \n",
    "ax     = 0.0;  % Initial guess for brackets. \n",
    "xx     = .2;%2*rand();%2.0; \n",
    "\n",
    "ftemp=@f1dim;\n",
    "ftemp2=@df1dim;\n",
    "\n",
    "[ax, xx, bx, fa1, fc1, fb1] = mnbrak(ax, xx, ftemp, stim, resp, order, avgs);\n",
    "%[ax,xx,bx]\n",
    "%plotalonglinemin(ax,bx,ftemp);\n",
    "[fret, xmin] = dbrent(ax,xx,bx,ftemp,ftemp2,TOL, stim, resp, order, avgs); \n",
    "%xmin\n",
    "%plot([xmin],[fret],'ro','LineWidth',7); \n",
    "%drawnow;\n",
    "%hold off;\n",
    "xi     = xi.*xmin;\n",
    "p      = p + xi;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "def frprmn():\n",
    "    ITMAX = 1000\n",
    "    fp = eval(func, p, stim, resp, order)\n",
    "    xi = eval(dfunc, p, stim, avgs, order)    \n",
    "    exitCondition = 0\n",
    "    g  = -xi\n",
    "    h  = g\n",
    "    xi = g\n",
    "    besttest = 1000\n",
    "    flist=[]\n",
    "    ftestlist=[]\n",
    "    tally = 0\n",
    "    \n",
    "    # Loop over iterations of minimization\n",
    "    for its in range(ITMAX):\n",
    "        display('Iteration' str(its))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [pbest, flist, ftestlist] = frprmn(p, func, dfunc, stim, resp, teststim, testresp, order, avgs, fittype)\n",
    "\n",
    "ITMAX = 1000;\n",
    "fp = feval(func, p, stim, resp, order);\n",
    "xi = feval(dfunc, p, stim, avgs, order);\n",
    "exitCondition = 0;\n",
    "g  = -xi;\n",
    "h  = g;\n",
    "xi = g;\n",
    "besttest = 1000;\n",
    "flist=[];\n",
    "ftestlist=[];\n",
    "tally = 0;\n",
    "\n",
    "% Loop over iterations of minimization\n",
    "for its=1:ITMAX,\n",
    "    disp(['Iteration ' num2str(its)]);\n",
    "  \n",
    "    [p, xi, fret] = dlinmin(p, xi, func, dfunc, stim, resp, order, avgs);\n",
    "    flist(its)=fret;\n",
    "    if fittype==0\n",
    "        ftestlist(its)=feval(func, p, teststim, testresp, order);\n",
    "    end\n",
    "    \n",
    "    \n",
    "%    figure(1)\n",
    "%    plot(flist)\n",
    "%    if fittype==0\n",
    "%        hold on\n",
    "%        plot(ftestlist,'r')\n",
    "%        hold off\n",
    "%    end\n",
    "%    drawnow\n",
    "\n",
    "    \n",
    "    if fittype==0\n",
    "        \n",
    "        if ftestlist(its)<besttest*.999999  || its<=2     % train validation test validation overfitting line goes up\n",
    "            besttest = ftestlist(its);\n",
    "            pbest = p;\n",
    "            tally=0;\n",
    "        else\n",
    "            tally = tally+1;\n",
    "        end\n",
    "        \n",
    "        if tally==10 || its==400\n",
    "            disp(tally)\n",
    "            disp(its)\n",
    "            disp('min of test set found');\n",
    "            exitCondition = 1;\n",
    "            break;\n",
    "        end\n",
    "        \n",
    "    else\n",
    "        [Nsamples,Ndim] = size(stim);\n",
    "        J = reshape(p(Ndim+2:Ndim+1+Ndim^2),[Ndim,Ndim]);\n",
    "        [evecs,evals]=eig(J);\n",
    "        [EV,inds] = sort((diag(evals)));\n",
    "        disp(num2str([min(EV) , max(EV)]));\n",
    "        if its==200\n",
    "            pbest = p;\n",
    "            disp('stopping algorithm');\n",
    "            exitCondition = 1;\n",
    "            break;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    xi = feval(dfunc, p, stim, avgs, order);\n",
    "    gg = sum(g.^2);\n",
    "    dgg = sum( (xi + g).*xi );   % This statement for Polak-Ribiere\n",
    "    % dgg = sum( xi.^2);         % This statement for Fletcher-Reeves\n",
    "    if gg == 0,            % Unlikely.  If gradient is exactly zero then\n",
    "        exitCondition = 2;   % we are already done.\n",
    "        disp('Gradient equal to zero, exiting frprmn.');\n",
    "        break;\n",
    "    end\n",
    "    gam = dgg/gg;\n",
    "    g = -xi;\n",
    "    h = g + gam.*h;\n",
    "    xi = h;\n",
    "end\n",
    "if exitCondition == 0,\n",
    "    disp('Too many iterations in frprmn');\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order1 = 2\n",
    "pfinal = mnefit(trainstim,trainresp,order1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function df = dlogloss(p, stim, avgs, order)\n",
    "\n",
    "[Nsamples,Ndim] = size(stim);\n",
    "\n",
    "ptemp = p(2:Ndim+1);\n",
    "if order>1\n",
    "    J = reshape(p(Ndim+2:Ndim+1+Ndim^2),[Ndim,Ndim]);\n",
    "end\n",
    "\n",
    "if order==1\n",
    "    pSpike = 1./(1+exp(p(1)+stim*ptemp'));  % Nsamples x 1\n",
    "    averages = mean(pSpike);\n",
    "    averages(2:Ndim+1,1) = stim'*pSpike/Nsamples;\n",
    "elseif order==2\n",
    "    pSpike = 1./(1+exp(p(1)+stim*ptemp'+sum(stim.*(stim*J),2)));  % Nsamples x 1\n",
    "    averages = mean(pSpike);\n",
    "    averages(2:Ndim+1,1) = stim'*pSpike./Nsamples;\n",
    "    temp = stim'*(repmat(pSpike,[1,Ndim]).*stim)./Nsamples;  % Ndim x Ndim\n",
    "    temp = reshape(temp,[Ndim^2,1]);\n",
    "    averages(Ndim+2:Ndim+1+Ndim^2) = temp;    \n",
    "end\n",
    "%display(size(pSpike))\n",
    "%display(size(averages))\n",
    "%display(size(avgs))\n",
    "\n",
    "df = (avgs - averages)';  % 1 x Ndim\n",
    "%display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import MNEfit as mnefit\n",
    "#import scipy as sp\n",
    "#import scipy.optimize as opt\n",
    "#mport logLossFuncs as LLF\n",
    "#pfinal = opt.fmin_cg(logLoss,pstart,fprime=dlogLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape((1.0*stim.T*resp)/(Nsamples*1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#initialize params:\n",
    "pstart = sp.log(1/avgs[0,0] - 1)\n",
    "pstart = sp.hstack((pstart,(.001*(2*sp.random.rand(Ndim)-1))))\n",
    "if(order > 1):\n",
    "    temp = .0005*(2*sp.random.rand(Ndim,Ndim)-1)\n",
    "    pstart = sp.hstack((pstart,sp.reshape(temp+temp.T,(1,Ndim**2))[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.multiply(a,trainstim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.dot(np.transpose(trainstim),b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.transpose(trainresp)*trainstim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "print(np.shape(trainstim))\n",
    "print(np.shape(teststim))\n",
    "print(np.shape(masterstim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### \n",
    "resp_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tic():\n",
    "    #Homemade version of matlab tic and toc functions\n",
    "    import time\n",
    "    global startTime_for_tictoc\n",
    "    startTime_for_tictoc = time.time()\n",
    "\n",
    "def toc():\n",
    "    import time\n",
    "    if 'startTime_for_tictoc' in globals():\n",
    "        print (\"Elapsed time is \" + str(time.time() - startTime_for_tictoc) + \" seconds.\")\n",
    "    else:\n",
    "        print (\"Toc: start time not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jack in range(njack):    #loop over all njacks to resample and fix outliers in tsne    \n",
    "    Ntest = int(master_samples/njack)    #  rounds the Ntest to the nearest integers \n",
    "    ind = range(jack*Ntest,(jack+1)*Ntest)\n",
    "    teststim = masterstim[jack*Ntest : (jack+1)*Ntest, :]\n",
    "    testresp = masterresp[jack*Ntest : (jack+1)*Ntest]\n",
    "    trainstim = np.delete(masterstim, ind, axis = 0) \n",
    "    trainresp = np.delete(masterresp, ind)\n",
    "    \n",
    "    # Start optimization: look for highest P(resp/stim)=1/(1+exp(a+sh+s^t*J*s)^-1\n",
    "    display('Starting optimization')\n",
    "    tic()\n",
    "    #celltype = '';  #ignore this\n",
    "    \n",
    "    #MNEfit(stim, resp, teststim, testresp, celltype, cellnum, jack, order, Nd, fittype);\n",
    "    [Nsamples_2,Ndim_2] = np.shape(trainstim)\n",
    "    psp = np.mean(trainresp)   #constant parameter a\n",
    "    ??????avg = (np.transpose(trainstim)*trainresp)/Nsamples_2  # h: linear\n",
    "    \n",
    "avg_1 = mean(avg,2); \n",
    "avgs = [psp;avg_1]; % J: non-linear \n",
    "if order>1\n",
    "    avgsqrd = trainstim'*(repmat(trainresp,[1,Ndim_2]).*trainstim)/Nsamples_2;  % Ndim x Ndim (320x320)\n",
    "    avgsqrd = reshape(avgsqrd,[Ndim_2^2,1]); \n",
    "    avgs = [avgs;avgsqrd]; % avgs= [a,h,J]\n",
    "end\n",
    "\n",
    "% Initialize parameters. This is to set a random staring point on optimization curve. \n",
    "\n",
    "pstart = log(1/avgs(1)-1);  %pstart(a)\n",
    "pstart(2:Ndim_2+1) = .001*(2*rand([1,Ndim_2])-1); %pstart(h)\n",
    "if order>1\n",
    "    temp = .001*(2*rand([Ndim_2,Ndim_2])-1); % pstart(J)\n",
    "    pstart(Ndim_2+2:length(pstart)+Ndim_2^2) = reshape((temp+temp'),[1,Ndim_2^2]);\n",
    "    clear temp;\n",
    "end\n",
    "\n",
    "% Run conjugate gradient algorithm \n",
    "%Conjugate= method of optimization to not to miss the min on curve\n",
    "%frprmn= Get derivative to locate the global minima of variables \n",
    "%logloss=Near probability model to a set of binary labeled examples. \n",
    "%dloggloss=Gradient of the log loss function\n",
    "\n",
    "% Pass pstart (intial number) to logloss and dlogloss...for every point to get pfinal\n",
    "pfinal = frprmn(pstart, @logloss, @dlogloss, trainstim, trainresp, teststim, testresp, order, avgs, Nd, fittype);\n",
    "\n",
    "%Save results\n",
    "       \n",
    "save(['B952_P1S1_cell' num2str(cellnum) '_5stims' '_Nlags' num2str(Nlags) '_nfft128_Nf16' '_jack_' num2str(jack) '_of_' num2str(njack) '.mat'],'pfinal');\n",
    "  \n",
    "%end\n",
    "\n",
    "disp(['Optimization took ' num2str(toc/60) ' minutes']);\n",
    "\n",
    "% This a, h,J are coresponding to pbest=min of test set\n",
    "h=pfinal(2:Nlags*Nf+1); % h=2:321\n",
    "\n",
    "J=pfinal(Nlags*Nf+2:end); % this is the covariance matrix J=322:end \n",
    "\n",
    "[V,D] = eig(reshape(J,Nlags*Nf,Nlags*Nf)); %[V,D] = eig(A) produces a diagonal matrix D of eigenvalues and eigenvectors \n",
    "\n",
    "%Plot the results and save the figures\n",
    "figure\n",
    "subplot(3,3,1)\n",
    "imagesc(reshape(h,Nf,Nlags))\n",
    "axis xy\n",
    "title('h')\n",
    "xlabel('t');\n",
    "ylabel('f');\n",
    " \n",
    "subplot(3,3,2)\n",
    "imagesc(reshape(J,Nlags*Nf,Nlags*Nf))\n",
    "axis xy\n",
    "axis square\n",
    "title('J')\n",
    "\n",
    "subplot(3,3,3)\n",
    "eigenvalues = diag(D);\n",
    "[eigenvalues_sorted,index] = sort(eigenvalues); %sorts the elements of eigenvalues in ascending order.\n",
    "plot(eigenvalues_sorted,'o');\n",
    "title('J Eigvalue Matrix')\n",
    "\n",
    "\n",
    "subplot(3,3,4)\n",
    "eig_sorted_1 = V(:,index(1)); \n",
    "imagesc(reshape(eig_sorted_1,Nf,Nlags))\n",
    "axis xy\n",
    "title('eig vect 1')\n",
    "xlabel('t');\n",
    "ylabel('f');\n",
    "\n",
    "subplot(3,3,5)\n",
    "eig_sorted_2=V(:,index(2)); \n",
    "imagesc(reshape(eig_sorted_2,Nf,Nlags))\n",
    "axis xy\n",
    "title('eig vect 2')\n",
    "xlabel('t');\n",
    "ylabel('f');\n",
    "\n",
    "subplot(3,3,6)\n",
    "eig_sorted_3=V(:,index(3)); \n",
    "imagesc(reshape(eig_sorted_3,Nf,Nlags))\n",
    "axis xy\n",
    "title('eig vect 3')\n",
    "xlabel('t');\n",
    "ylabel('f');\n",
    "\n",
    "subplot(3,3,7)\n",
    "eig_sorted_end=V(:,index(end));\n",
    "imagesc(reshape(eig_sorted_end,Nf,Nlags))\n",
    "axis xy\n",
    "title('eig vect end')\n",
    "xlabel('t');\n",
    "ylabel('f');\n",
    "\n",
    "subplot(3,3,8)\n",
    "eig_sorted_end_1=V(:,index(end-1));\n",
    "imagesc(reshape(eig_sorted_end_1,Nf,Nlags))\n",
    "axis xy\n",
    "title('eig vect end-1')\n",
    "xlabel('t');\n",
    "ylabel('f');\n",
    "\n",
    "subplot(3,3,9)\n",
    "eig_sorted_end_2=V(:,index(end-2));\n",
    "imagesc(reshape(eig_sorted_end_2,Nf,Nlags))\n",
    "axis xy\n",
    "title('eig vect end-2')\n",
    "xlabel('t');\n",
    "ylabel('f');\n",
    "\n",
    "figure_name = (['B952_' num2str(cellnum) 'your figure name' '_Nlags' num2str(Nlags) '_nfft128_Nf16' '_jack_' num2str(jack) '_of_' num2str(njack)]); \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raster_cell__stim(spikes, trials, clusterID,\n",
    "                          stim, period, rec, fs, ax=None, stim_ref='stim', **kwargs):\n",
    "    stim_trials = trials[trials['stimulus'] == stim]\n",
    "    ntrials = len(stim_trials)\n",
    "    stim_starts = stim_trials['time_samples'].values\n",
    "    stim_ends = stim_trials['stimulus_end'].values\n",
    "    stim_end_seconds = np.unique((stim_ends - stim_starts) / fs)[0]\n",
    "    if stim_ref == 'stim':\n",
    "        window = [period[0], stim_end_seconds + period[1]]\n",
    "    elif stim_ref == 'abs':\n",
    "        window = [period[0], period[1]]\n",
    "    raster_data = []\n",
    "    for trial, start in enumerate(stim_starts):\n",
    "        sptrain = get_spiketrain(rec, start, clusterID, spikes, window, fs)\n",
    "        raster_data.append(sptrain)\n",
    "    ax = do_raster(raster_data, window, [0, stim_end_seconds], ntrials, ax, **kwargs)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as opt\n",
    "import numpy as np\n",
    "\n",
    "def log_loss(p, stim, resp, order):\n",
    "    #get number of samples and dimensionality of stimulus\n",
    "    Nsamples, Ndim = stim.shape\n",
    "    resp = np.reshape(resp, (-1))\n",
    "    \n",
    "    #unpack p: (var names match names in Fitzgerald paper)\n",
    "    a = p[0]\n",
    "    h = p[1:Ndim+1].T\n",
    "    \n",
    "    #case: second order calculation --> need J\n",
    "    if order > 1:\n",
    "        #reshape J into Ndim x Ndim matrix:\n",
    "        J = np.reshape(p[Ndim+1:Ndim+1+Ndim**2], (Ndim,Ndim)).T\n",
    "    \n",
    "    if order == 1:\n",
    "        f1 = 1 + np.exp( a + stim.dot(h))\n",
    "        f0 = 1 + np.exp(-a - stim.dot(h))\n",
    "    else:\n",
    "        f1 = 1 + np.exp( a + stim.dot(h) + (np.sum(stim * (stim.dot(J)),1)))\n",
    "        f0 = 1 + np.exp(-a - stim.dot(h) - (np.sum(stim * (stim.dot(J)),1)))\n",
    "    \n",
    "    F1 = resp * np.log(f1)\n",
    "    F0 = (1 - resp) * np.log(f0)\n",
    "    F1[np.isnan(F1)] = 0\n",
    "    F0[np.isnan(F0)] = 0\n",
    "    return np.mean(F0 + F1)\n",
    "\n",
    "def d_log_loss(p,stim,avgs,order):\n",
    "    #get number of samples and dimensionality of stimulus\n",
    "    Nsamples, Ndim = stim.shape\n",
    "    \n",
    "    #unpack p: (var names match names in Fitzgerald paper)\n",
    "    a = p[0]\n",
    "    h = p[1:Ndim+1].T\n",
    "    \n",
    "    #case: second order calculation --> need J\n",
    "    if order > 1:\n",
    "        J = np.reshape(p[Ndim+1:Ndim+1+Ndim**2], (Ndim,Ndim))\n",
    "        \n",
    "    if order == 1:\n",
    "        pSpike = 1.0 / (1.0 + np.exp(a + stim.dot(h))) #Nsamples x 1\n",
    "        averages = np.hstack((np.mean(pSpike), stim.T.dot(pSpike) / Nsamples))\n",
    "    elif order == 2:\n",
    "        \n",
    "        pSpike = 1.0 / (1.0 + np.exp(a + stim.dot(h) + (np.sum(stim * (stim.dot(J)),1))))\n",
    "        averages = np.zeros(1+Ndim+Ndim**2)\n",
    "        averages[0] = np.mean(pSpike)\n",
    "        averages[1:Ndim+1] = stim.T.dot(pSpike) / Nsamples #ave number of spikes for each stim dimension\n",
    "        \n",
    "        temp = (stim.T.dot(np.tile(np.reshape(pSpike, (Nsamples, 1)), (1,Ndim)) * stim)) / Nsamples  #ave number of spikes for each stim correlation\n",
    "        temp = np.reshape(temp,[Ndim**2,1])\n",
    "        averages[Ndim+1:Ndim+1+Ndim**2] = np.reshape(temp, Ndim**2)\n",
    "        \n",
    "    return (np.squeeze(avgs) - averages)\n",
    "\n",
    "def constrained_averages(stim, resp, order):\n",
    "    Nsamples, Ndim = stim.shape\n",
    "    psp = np.mean(resp) #spike probability\n",
    "    avg = stim.T.dot(resp) / Nsamples\n",
    "    avgs = np.vstack((psp,avg))\n",
    "    if order > 1 :\n",
    "        avgsqrd = stim.T.dot(np.tile(resp, (1,Ndim)) * stim) / Nsamples\n",
    "        avgsqrd = np.reshape(avgsqrd,(Ndim**2,1))\n",
    "        avgs = np.vstack((avgs,avgsqrd))\n",
    "    return avgs\n",
    "\n",
    "def rand_pstart(avgs, order, Ndim):\n",
    "    pstart = np.log(1.0 / avgs[0] - 1.0)\n",
    "    pstart = np.hstack((pstart,(.001*(2*np.random.rand(Ndim)-1))))\n",
    "    if order > 1:\n",
    "        temp = .0005 * (2 * np.random.rand(Ndim,Ndim) - 1) # for symmetry\n",
    "        pstart = np.hstack((pstart, np.reshape(temp + temp.T, Ndim**2)))\n",
    "    return pstart\n",
    "    \n",
    "class IterCounter(object):\n",
    "    def __init__(self):\n",
    "        self.n_iters = 1\n",
    "        print '{0:5s}'.format('Iters')\n",
    "    def callback(self, xk):\n",
    "        print '{0:5d}'.format(self.n_iters)\n",
    "        self.n_iters += 1\n",
    "    \n",
    "class OverfitException(Exception):\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "        \n",
    "class OverfitStopper(object):\n",
    "    def __init__(self, test_stim, test_resp, order):\n",
    "        self.test_stim = test_stim\n",
    "        self.test_resp = test_resp\n",
    "        self.order = order\n",
    "        self.n_iters = 1\n",
    "        self.best_ll = np.inf\n",
    "        self.best_p = 0\n",
    "        self.test_tally = 0\n",
    "        print '{0:5s}   {1:5s}   {2:9s}'.format('Iters', 'tally', 'll(test)')\n",
    "        \n",
    "    def callback(self, pk):\n",
    "        ll_test_k = log_loss(pk, self.test_stim, self.test_resp, self.order)\n",
    "        print '{0:5d}   {1:5d}   {2: 3.6f}'.format(self.n_iters, self.test_tally, ll_test_k)\n",
    "        if self.n_iters <= 2 or ll_test_k < self.best_ll:\n",
    "            self.best_ll = ll_test_k\n",
    "            self.best_p = pk\n",
    "            self.test_tally = 0\n",
    "        else:\n",
    "            self.test_tally += 1\n",
    "        \n",
    "        if self.test_tally >= 10:\n",
    "            print 'minimum of test set found'\n",
    "            raise OverfitException(self.best_p)\n",
    "        \n",
    "        self.n_iters += 1\n",
    "\n",
    "def MNEfit(stim, resp, order, pstart=None):\n",
    "\n",
    "    stim = np.array(stim, dtype=float)\n",
    "    resp = np.array(resp, dtype=float)\n",
    "\n",
    "    Nsamples, Ndim = stim.shape\n",
    "    avgs = constrained_averages(stim, resp, order)\n",
    "    \n",
    "    if pstart is None: #initialize params:\n",
    "        pstart = rand_pstart(avgs, order, Ndim)\n",
    "    \n",
    "    #redefine functions with fixed vals:\n",
    "    def logLoss(p):\n",
    "        return log_loss(p, stim, resp, order)\n",
    "    def dlogLoss(p):\n",
    "        return d_log_loss(p, stim, avgs, order)\n",
    "    \n",
    "    pfinal = opt.fmin_cg(logLoss, pstart, fprime=dlogLoss, \n",
    "                         callback=IterCounter().callback, maxiter=200)\n",
    "    \n",
    "    return pfinal\n",
    "\n",
    "def MNEfit_jackknives(stim, resp, order, pstart=None, jackknives=4, shuffle=True):\n",
    "\n",
    "    stim = np.array(stim, dtype=float)\n",
    "    resp = np.array(resp, dtype=float)\n",
    "    \n",
    "    Nsamples, Ndim = stim.shape #TODO: rename Nsamples to n_samples\n",
    "    assert resp.shape[0] == Nsamples\n",
    "    assert resp.shape[1] == 1\n",
    "    \n",
    "    if shuffle:\n",
    "        shuffled_indxs = range(Nsamples)\n",
    "        np.random.shuffle(shuffled_indxs)\n",
    "        stim = stim[shuffled_indxs,:]\n",
    "        resp = resp[shuffled_indxs,:]\n",
    "    \n",
    "    for jackknife in range(jackknives):\n",
    "        test_stim = stim[jackknife::jackknives,:]\n",
    "        test_resp = resp[jackknife::jackknives,:]\n",
    "        train_stim = stim[np.mod(np.arange(Nsamples)-jackknife, jackknives) != 0,:]\n",
    "        train_resp = resp[np.mod(np.arange(Nsamples)-jackknife, jackknives) != 0,:]\n",
    "        \n",
    "        avgs = constrained_averages(train_stim, train_resp, order)\n",
    "\n",
    "        if pstart is None: #initialize params:\n",
    "            pstart = rand_pstart(avgs, order, Ndim)\n",
    "            \n",
    "        #redefine functions with fixed vals:\n",
    "        def logLoss(p):\n",
    "            return log_loss(p, train_stim, train_resp, order)\n",
    "        def dlogLoss(p):\n",
    "            return d_log_loss(p, train_stim, avgs, order)\n",
    "\n",
    "        try:\n",
    "            pfinal = opt.fmin_cg(logLoss, pstart, fprime=dlogLoss,\n",
    "                                 callback=OverfitStopper(test_stim, test_resp, order).callback,\n",
    "                                 maxiter=200)\n",
    "        except OverfitException as e:\n",
    "            pfinal = e.p\n",
    "        \n",
    "        if jackknife == 0:\n",
    "            all_pfinals = np.zeros((jackknives, len(pstart)))\n",
    "        all_pfinals[jackknife, :] = pfinal\n",
    "    \n",
    "    return all_pfinals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
